////////////////////////////////////////////////////////////////////////////////
/// This should be a very simple demo of rdkafka - as a side effect, this could
/// be also a very quick tutorial of Kafka itself.
///
/// I took as basis the original Kafka documentation, which can be found at:
///
/// https://kafka.apache.org/documentation/
///
////////////////////////////////////////////////////////////////////////////////

#include <iostream>
#include <string>
#include <thread>
#include <librdkafka/rdkafka.h>
#include <string.h>
#include <unistd.h>
#include <cstdio>

bool isRunning = true;

void message_receipt_cbk(rd_kafka_t * kf_producer,
        const rd_kafka_message_t * kf_message, void *opaque) {
    if (kf_message->err)
        std::cout << "Message delivery failed: %s"
                << rd_kafka_err2str(kf_message->err);
    else
        std::cout << "Message delivered (" << kf_message->len << " bytes, "
                "partition " << kf_message->partition << ")" << std::endl;
}

rd_kafka_t * createKafkaProducer() {
    // The configuration structure
    rd_kafka_conf_t * kf_conf;
    char errstr[512];

    // First thing is to create a producer.
    kf_conf = rd_kafka_conf_new();
    rd_kafka_conf_res_t kf_conf_result;

    // First thing is to create a producer.
    kf_conf = rd_kafka_conf_new();

    // And we need to configure the producer
    // All producer configuration can be found in:
    // https://kafka.apache.org/documentation/#producerconfigs
    kf_conf_result = rd_kafka_conf_set(kf_conf, "compression.codec", "snappy",
            errstr, sizeof(errstr));
    kf_conf_result = rd_kafka_conf_set(kf_conf, "bootstrap.servers",
            "127.0.0.1", errstr, sizeof(errstr));
    kf_conf_result = rd_kafka_conf_set(kf_conf, "batch.num.messages", "100",
            errstr, sizeof(errstr));

    // Set the callback to inform the result of every message sent by this
    // producer.
    rd_kafka_conf_set_dr_msg_cb(kf_conf, message_receipt_cbk);

    return rd_kafka_new(RD_KAFKA_PRODUCER, kf_conf, errstr, 512);
}

rd_kafka_t * createKafkaConsumer() {
    // The configuration structure
    rd_kafka_conf_t * kf_conf;
    char errstr[512];

    // First thing is to create a producer.
    kf_conf = rd_kafka_conf_new();
    rd_kafka_conf_res_t kf_conf_result;

    // First thing is to create a producer.
    kf_conf = rd_kafka_conf_new();

    // And we need to configure the producer
    // All producer configuration can be found in:
    // https://kafka.apache.org/documentation/#producerconfigs
    kf_conf_result = rd_kafka_conf_set(kf_conf, "compression.codec", "snappy",
            errstr, sizeof(errstr));
    kf_conf_result = rd_kafka_conf_set(kf_conf, "bootstrap.servers",
            "127.0.0.1", errstr, sizeof(errstr));
    kf_conf_result = rd_kafka_conf_set(kf_conf, "batch.num.messages", "100",
            errstr, sizeof(errstr));

    // Need to set this extra group.id parameter - rdkafka will return error
    // when subscribing to topics if this parameter is not set.
    kf_conf_result = rd_kafka_conf_set(kf_conf, "group.id", "demo-group",
            errstr, sizeof(errstr));

    // No need to set message delivery callbacks

    return rd_kafka_new(RD_KAFKA_CONSUMER, kf_conf, errstr, 512);
}

rd_kafka_topic_t * createTopic(const std::string & topic,
        rd_kafka_t * kf_producer) {
    // All topic configuration can be found at:
    // https://kafka.apache.org/documentation/#topic-config
    rd_kafka_topic_conf_t * kf_topic_conf = rd_kafka_topic_conf_new();
    return rd_kafka_topic_new(kf_producer, topic.c_str(), nullptr);
}

void destroyKafkaEntity(rd_kafka_t * kf_entity) {
    // Not sure if this also destroy parameters - valgrind is complaining about
    // unreleased  memory. The documentation doesn't mention anything.
    rd_kafka_destroy(kf_entity);
}

void destroyTopic(rd_kafka_topic_t * kf_topic) {
    rd_kafka_topic_destroy(kf_topic);
}

int sendMessage(std::string & message, rd_kafka_topic_t * kf_topic) {

    if (message.length() == 0) {
        return 0;
    }

    // Partition variable - this can be fixed (as in this demo), can be
    // generated by rd_kafka_msg_partitioner_*,  or RD_KAFKA_PARTITION_UA which
    // won't assign any partition to this message.
    int32_t kf_partition = RD_KAFKA_PARTITION_UA;

    // Possible flags are:
    // - RD_KAFKA_MSG_F_BLOCK: block rd_kafka_produce call.
    // - RD_KAFKA_MSG_F_FREE: free payload content after sending it.
    // - RD_KAFKA_MSG_F_COPY: copy payload content so that caller can reuse it.
    int kf_part_msg_flags = RD_KAFKA_MSG_F_FREE;

    char * msg_payload = new char[message.length() + 1];
    memset(msg_payload, 0, message.length() + 1);
    strcpy(msg_payload, message.c_str());

    size_t msg_payload_size = message.length();

    // Let's send a message
    // No keys - I don't know how to use them right now - sorry!
    return rd_kafka_produce(kf_topic, kf_partition, kf_part_msg_flags,
            msg_payload, msg_payload_size, nullptr, 0, nullptr);
}

void consumerCallback(rd_kafka_message_t *rkmessage, void *opaque) {
    std::cout << "cons) Received a message" << std::endl;
    if (rkmessage == nullptr || (rkmessage->err != RD_KAFKA_RESP_ERR_NO_ERROR)) {
        return;
    }
    std::string topicName = rd_kafka_topic_name(rkmessage->rkt);
    std::string message((char*) rkmessage->payload, rkmessage->len);

    char * key = (char*) rkmessage->key;
    std::cout << "cons) Received message for topic: " << topicName << std::endl;
    std::cout << "cons) Key: " << ((key != nullptr ? key : "no key was provided"))
            << std::endl;
    std::cout << "cons) Message: " << message << std::endl;
}

void startConsumer() {
    std::cout << "Starting consumer" << std::endl;
    rd_kafka_t * kf_consumer = createKafkaConsumer();

    // Now we have our consumer. We need to create a list of topics to subscribe
    rd_kafka_topic_partition_list_t * kf_topics = rd_kafka_topic_partition_list_new(1);
    rd_kafka_topic_partition_list_add(kf_topics, "^demo-default-topic.*", 0);

    // And subscribe!
    rd_kafka_resp_err_t ret = rd_kafka_subscribe(kf_consumer, kf_topics);
    std::cout << "Result: " << ret << std::endl;


    // Another possibility is to use rd_kafka_consumer_callback - it will
    // retrieve all the requested messages faster than any other function (as
    // the documentation says)
    while (isRunning) {
        consumerCallback(rd_kafka_consumer_poll(kf_consumer, 10000), nullptr);
    }
    std::cout << "Exitting consumer" << std::endl;

    // Destroy everything
    rd_kafka_unsubscribe(kf_consumer);
    rd_kafka_topic_partition_list_destroy(kf_topics);
    destroyKafkaEntity(kf_consumer);
}

int main(void) {
    // Quick explanation:
    // Kafka is build around four core entities:
    //  - Producers: almost self-explanatory, these are the elements that, well,
    //      generate messages to be published.
    //  - Consumers: the producer counterpart - these elements read messages
    //  - Streams processors: elements that transform messages between message
    //      streams, playing a consumer role at one end, doing something to
    //      those messages and then sending the results to another stream as a
    //      producer.
    //  - Connectors: Like "templates" - these elements are reusable producer/
    //      consumers that connects specific topics to applications.
    // Now, simply put: messages are published in topics, and they can be
    // retrieved individually or in chunks of timeslots.

    rd_kafka_t * kf_producer = createKafkaProducer();

    // Now we have our producer. We need to create a topic so that we
    // can send messages.
    rd_kafka_topic_t * kf_topic = createTopic("demo-default-topic.xis",
            kf_producer);

    std::thread thr(startConsumer);

    //
    // We are almost ready to send a message.
    // Now we need to create the actual message and select a partition
    //
    std::string message;
    std::cin >> message;
    while (message != "-1") {
        std::cout << "prod) Sending message: " << message << std::endl;
        int ret = sendMessage(message, kf_topic);
        std::cin >> message;
    }
    isRunning = false;
    // Flush everything and wait 10 second for this task to finish.
    rd_kafka_flush(kf_producer, 10 * 1000);

    thr.join();
    // At the end we should call
    destroyTopic(kf_topic);
    destroyKafkaEntity(kf_producer);
}
